######################################## Course 1: Graphical Exploratory Data Analysis ########################################

plt.hist
sns.swarmplot

--------------------------------
Exploratory data analysis (EDA) : organizing, plotting, summarizing

- plotting a histogram
import matplotlib.pyplot as plt
plt.hist
plt.xlabel
plt.ylabel

import seaborn as sns
sns.set()
plt.hist
plt.xlabel=('
plt.ylabel

-------------------------------------------- exercise
# Import plotting modules
import matplotlib.pyplot as plt
import seaborn as sns

# Set default Seaborn style
sns.set()

# Plot histogram of versicolor petal lengths
_ = plt.hist(versicolor_petal_length)

# Label axes
_ = plt.xlabel('petal length (cm)')
_ = plt.ylabel('count')

# Show histogram
plt.show()

# Import numpy
import numpy as np

# Compute number of data points: n_data
n_data = len(versicolor_petal_length)

# Number of bins is the square root of number of data points: n_bins
n_bins = np.sqrt(n_data)

# Convert number of bins to integer: n_bins
n_bins = int(n_bins)

# Plot the histogram
_ = plt.hist(versicolor_petal_length, bins=n_bins)

# Label axes
_ = plt.xlabel('petal length (cm)')
_ = plt.ylabel('count')

# Show histogram
plt.show()
-------------------------------------------

Plot all of your data: Bee swarm plots

_=sns.swarmplot(x='state',y='dem_share',data=df_swing)
_=plt.xlabel('state')
_=plt.ylabel('percent of vote for Obama')




Plot all of your data: ECDFs
- Empirical cumulative distribution function (ECDF)

# Making an ECDF
import numpy as np
x=np.sort(df_swing['dem_share'])
y=np.array(1,len(x)+1) / lex(x)
_=plt.hist(x,y,marker='.',linestyle='none')
_=plt.xlabel('xxx')
_=plt.ylabel('xxx')
plt.margins(0.02) # keep data off plot edges


def ecdf(data):
    """Compute ECDF for a one-dimensional array of measurements."""
    # Number of data points: n
    n = len(data)

    # x-data for the ECDF: x
    x = np.sort(data)

    # y-data for the ECDF: y
    y = np.arange(1, n+1) / n

    return x, y


# Compute ECDF for versicolor data: x_vers, y_vers
x_vers, y_vers = ecdf(versicolor_petal_length)

# Generate plot
_ = plt.plot(x_vers,y_vers,marker='.',linestyle='none')

# Label the axes
_=plt.xlabel('versicolor_petal_length')
_=plt.ylabel('ECDF')


# Display the plot

plt.show()


# Compute ECDFs
x_set,y_set = ecdf(setosa_petal_length)
x_vers,y_vers = ecdf(versicolor_petal_length)
x_virg,y_virg=ecdf(virginica_petal_length)


# Plot all ECDFs on the same plot
_=plt.plot(x_set,y_set,marker='.',linestyle='none')
_=plt.plot(x_vers,y_vers,marker='.',linestyle='none')
_=plt.plot(x_virg,y_virg,marker='.',linestyle='none')


# Annotate the plot
plt.legend(('setosa', 'versicolor', 'virginica'), loc='lower right')
_ = plt.xlabel('petal length (cm)')
_ = plt.ylabel('ECDF')

# Display the plot
plt.show()

######################################## Course 2: Quantitative Exploratory Data Analysis ########################################
# Introduction to summary statistics: The sample mean and median
mean_length_vers=np.mean(versicolor_petal_length)

# Percentiles, outliers, and box plots
np.percentile(data['column'],[25,50,75])

import matplotlib.pyplot as plt
import seaborn as sns
_=sns.boxplot(x='',y='',data=df) -- Never forget the data=
_=plt.xlabel('xx')
_=plt.ylabel('xx')

# Variance and standard deviation
np.var()
np.std()


-- exercise
# Array of differences to mean: differences
differences = versicolor_petal_length - np.mean(versicolor_petal_length)

# Square the differences: diff_sq
diff_sq = differences**2

# Compute the mean square difference: variance_explicit
variance_explicit = np.mean(diff_sq)

# Compute the variance using NumPy: variance_np
variance_np = np.var(versicolor_petal_length)

# Print the results
print(variance_explicit, variance_np)


# Covariance and the Pearson correlation coefficient
covariance: how to quanties vary together = 1/n (sum (xi-x-bar)(yi-y-bar))
pearson correlation coefficient = covariance/ (std of x) (std of y) = variability due to codependence / indenpendt variability

-- exercise
# Compute the covariance matrix: covariance_matrix
covariance_matrix = np.cov(versicolor_petal_length, versicolor_petal_width)

# Print covariance matrix
print(covariance_matrix)

# Extract covariance of length and width of petals: petal_cov
petal_cov = covariance_matrix[0,1] - Important!!!

# Print the length/width covariance
print(petal_cov)



def pearson_r(x, y):
    """Compute Pearson correlation coefficient between two arrays."""
    # Compute correlation matrix: corr_mat
    corr_mat =np.corrcoef(x,y)

    # Return entry [0,1]
    return corr_mat[0,1]

# Compute Pearson correlation coefficient for I. versicolor: r
r = pearson_r(versicolor_petal_length,versicolor_petal_width)

# Print the result
print(r)


######################################## Course 3: Thinking Probabilistically-- Discrete Variables ########################################
np.random.random()
np.random.seed() 
np.empty() --> empty array
np.random.binomial(n,p)
np.random.poisson(prob, size= )

________________________________________________________________________
Random number generators and hacker statistics
Hacker statistics: uses simulated repeated measurements to calculate the proabilities

np.random.random() : draw a number between 0 and 1

np.random.seed() 

# simulation 4 coins flip
n_all_head = 0 # initialize number of 4-heads trials
for _ in range(10000):
         heads= np.random.random(size=4) < 0.5
         n_heads = np.sum(heads)
         if n_head == 4:
            n_all_head += 1
n_all_head/10000

----- exercise ------------------------------------
# Seed the random number generator
np.random.seed(42)

# Initialize random numbers: random_numbers
# Initialize an empty array
random_numbers =np.empty(100000)

# Generate random numbers by looping over range(100000)
for i in range(100000):
    random_numbers[i] = np.random.random()

# Plot a histogram
_ = plt.hist(random_numbers)

# Show the plot
plt.show()

------------------------------------
def perform_bernoulli_trials(n, p):
    """Perform n Bernoulli trials with success probability p
    and return number of successes."""
    # Initialize number of successes: n_success
    n_success = 0

    # Perform trials
    for i in range(n):
        # Choose random number between zero and one: random_number
        random_number=np.random.random()

        # If less than p, it's a success so add one to n_success
        if random_number < p:
            n_success += 1

    return n_success

------------------------------------

# Seed random number generator
np.random.seed(42)

# Initialize the number of defaults: n_defaults
n_defaults = np.empty(1000)

# Compute the number of defaults
for i in range(1000):
    n_defaults[i] = perform_bernoulli_trials(100,0.05)


# Plot the histogram with default number of bins; label your axes
_ = plt.hist(n_defaults, normed=True)
_ = plt.xlabel('number of defaults out of 100 loans')
_ = plt.ylabel('probability')

# Show the plot
plt.show()

------------------------------------
# Compute ECDF: x, y
x, y = ecdf(n_defaults)

# Plot the CDF with labeled axes
_ = plt.plot(x, y, marker='.', linestyle='none')
_ = plt.xlabel('number of defaults out of 100')
_ = plt.ylabel('CDF')

# Show the plot
plt.show()

# Compute the number of 100-loan simulations with 10 or more defaults: n_lose_money
# Compute the total number of entries in your n_defaults array that were greater than or equal to 10.
n_lose_money = np.sum(n_defaults >= 10)

# Compute and print probability of losing money
print('Probability of losing money =', n_lose_money / len(n_defaults))
---------------------------------------------------------------
########################
Probability distributions and stories: The Binomial distribution
PMF probability mass function

np.random.binomial(n,p,size=xxx) # n: number of bernouli trials, p: sucess prob.

import matplotlib.pyplot as plt
import seaborn as sns
sns.set()
x,y=ecdf(samples)
_=plt.plot(x,y,marker='.',linestyle='none')
plt.margins(0.02)
_=plt.xlabel('number of success')
_=plt.ylabel('CDF')

------------------
# Compute bin edges: bins
# The bin edges can be computed using np.arange(), going from 0 to max(n_defaults) + 1.5
bins = np.arange(0, max(n_defaults) + 1.5) - 0.5

# Generate histogram
_ = plt.hist(n_defaults, normed=True, bins=bins)

# Label axes
_ = plt.xlabel('number of defaults out of 100 loans')
_ = plt.ylabel('PMF')

# Show the plot
plt.show()



---------------------------------------------------------------
#################################

Poisson processes and the Poisson distribution

- the timing the next event is completely indepdent of the previous one
- the number r of arrivals in a certain time interval

np.random.poisson(prob,size =xxxx)



# the Poisson CDF
samples = np.random.poisson(6,size=10000)
x,y = ecdf(samples)
_=plt.plot(x,y,marker='.',linestyple='none')
plt.margin(0.02)
_=plt.xlabel('number of successess')
_=plt.ylabel('CDF')


------- exercise
# Draw 10,000 samples out of Poisson distribution: samples_poisson
samples_poisson = np.random.poisson(10, size=10000)

# Print the mean and standard deviation
print('Poisson:     ', np.mean(samples_poisson),
                       np.std(samples_poisson))

# Specify values of n and p to consider for Binomial: n, p
# Make a list of the n and p values to consider for the Binomial distribution. Choose n = [20, 100, 1000] and p = [0.5, 0.1, 0.01] so that  is always 10.
n = [20, 100, 1000]
p = [0.5, 0.1, 0.01]

# Draw 10,000 samples for each n,p pair: samples_binomial
for i in range(3):
    samples_binomial = np.random.binomial(n[i], p[i], size=10000)

    # Print results
    print('n =', n[i], 'Binom:', np.mean(samples_binomial),
                                 np.std(samples_binomial))

--------------- exercise
# Draw 10,000 samples out of Poisson distribution: n_nohitters
# Draw 10000 samples from a Poisson distribution with a mean of 251/115
n_nohitters = np.random.poisson(251/115, size=10000)

# Compute number of samples that are seven or greater: n_large
# Determine how many of your samples had a result greater than or equal to 7 and assign to n_large
n_large = np.sum(n_nohitters >= 7)

# Compute probability of getting seven or more: p_large
p_large = n_large / 10000

# Print the result
print('Probability of seven or more no-hitters:', p_large)

######################################## Course 4: Thinking Probabilistically-- Continuous Variables ########################################
samples = np.random.normal(mean,std,size = 10000)




___________________________________________________________________
PDF probability density function

---- Introduction to the Normal distribution

import numpy as np
mean = np.mean(xxx)
std=np.std(xxx)
samples = np.random.normal(mean,std,size = 10000)
x,y=ecdf(xxx)
x_theor,y_theor = ecdf(samples)

import matplotlib.pyplot as plt
import seaborn as sns
sns.set() ---> important
_=plt.plot(x,y,marker='',linestyle='')
_=plt.xlabel
_=plt.ylabel


---------------------------
# Draw 100000 samples from Normal distribution with stds of interest: samples_std1, samples_std3, samples_std10
samples_std1 = np.random.normal(20, 1, size=100000)
samples_std3 = np.random.normal(20, 3, size=100000)
samples_std10 = np.random.normal(20, 10, size=100000)

# Make histograms
_ = plt.hist(samples_std1, bins=100, normed=True, histtype='step')
_ = plt.hist(samples_std3, bins=100, normed=True, histtype='step')
_ = plt.hist(samples_std10, bins=100, normed=True, histtype='step')

# Make a legend, set limits and show plot
_ = plt.legend(('std = 1', 'std = 3', 'std = 10'))
plt.ylim(-0.01, 0.42)
plt.show()

# Generate CDFs
x_std1, y_std1 = ecdf(samples_std1)
x_std3, y_std3 = ecdf(samples_std3)
x_std10, y_std10 = ecdf(samples_std10)

# Plot CDFs
_ = plt.plot(x_std1, y_std1, marker='.', linestyle='none')
_ = plt.plot(x_std3, y_std3, marker='.', linestyle='none')
_ = plt.plot(x_std10, y_std10, marker='.', linestyle='none')

# Make a legend and show the plot
_ = plt.legend(('std = 1', 'std = 3', 'std = 10'), loc='lower right')
plt.show()





#### The Normal distribution: Properties and warnings

# Compute mean and standard deviation: mu, sigma
mu = np.mean(belmont_no_outliers)
sigma = np.std(belmont_no_outliers)

# Sample out of a normal distribution with this mu and sigma: samples
samples = np.random.normal(mu, sigma, size=10000)

# Get the CDF of the samples and of the data
x_theor, y_theor = ecdf(samples)
x, y = ecdf(belmont_no_outliers)

# Plot the CDFs and show the plot
_ = plt.plot(x_theor, y_theor)
_ = plt.plot(x, y, marker='.', linestyle='none')
_ = plt.xlabel('Belmont winning time (sec.)')
_ = plt.ylabel('CDF')
plt.show()


# Take a million samples out of the Normal distribution: samples
samples = np.random.normal(mu,sigma,size=1000000)

# Compute the fraction that are faster than 144 seconds: prob
prob = np.sum(samples <=144)/1000000

# Print the result
print('Probability of besting Secretariat:', prob)








